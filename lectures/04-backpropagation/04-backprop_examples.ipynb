{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND gate\n",
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "\n",
    "# AND\n",
    "y = np.array([0, 0, 0, 1], dtype=np.int8)\n",
    "\n",
    "# OR\n",
    "# y = np.array([0, 1, 1, 1], dtype=np.int8)\n",
    "\n",
    "# XOR\n",
    "# y = np.array([0, 1, 1, 0], dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting stuff\n",
    "def plot_inputs(X, y):\n",
    "    y_flat = y.flatten()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.scatter(X[y_flat == 0,1],X[y_flat == 0,2],color=\"blue\", marker=\"o\", label=\"Output: 0\")\n",
    "    ax.scatter(X[y_flat == 1,1],X[y_flat == 1,2],color=\"red\", marker=\"x\", label=\"Output: 1\")\n",
    "    ax.set_xlabel(\"$x_1$\")\n",
    "    ax.set_ylabel(\"$x_2$\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    return fig, ax\n",
    "\n",
    "def plot_decision(ax, w, colour=[0, 0, 0, 0.2], label=None):\n",
    "    # We get a 1 if w0 + w1x1 + w2x2 >= 0, and a 0 otherwise.\n",
    "    # solving for x2, we get x2 >= -(w0 + w1x1) / w2\n",
    "    if abs(w[2]) > 0:\n",
    "        slope = -w[1] / w[2]\n",
    "        intercept = -w[0] / w[2]\n",
    "        decision_x = np.array([-0.1, 1.1])\n",
    "        ax.plot(decision_x, decision_x * slope + intercept, color=colour, label=label)\n",
    "\n",
    "fig, ax = plot_inputs(X, y)\n",
    "leg = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1 # early choice, gives integer weights\n",
    "\n",
    "def step(v):\n",
    "    \"\"\"Heaviside step function\"\"\"\n",
    "    return (v >= 0).astype(int)\n",
    "\n",
    "# Initialize weights to zero\n",
    "w = np.zeros(3)\n",
    "\n",
    "y_hat = X @ w\n",
    "iter = 0\n",
    "\n",
    "while not all(y == y_hat):\n",
    "    # Visualize progress\n",
    "    plot_decision(ax, w)\n",
    "    print(f\"Iteration {iter}: w = {w}\")\n",
    "    \n",
    "    # one instance at a time\n",
    "    i = iter % 4\n",
    "    y_hat[i] = step(w.T @ X[i,:])\n",
    "    if y_hat[i] != y[i]:\n",
    "        w += eta * (y[i] - y_hat[i]) * X[i,:]\n",
    "    iter += 1\n",
    "\n",
    "print(f\"Final w = {w.flatten()}\")\n",
    "\n",
    "plot_decision(ax, w, \"green\", \"Final boundary\")\n",
    "ax.set_aspect(\"auto\")\n",
    "leg.remove()\n",
    "leg = ax.legend()\n",
    "ax.set_title(f\"Solution converged after {iter} iterations\")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify XOR solution\n",
    "# X is unchanged from prior inputs\n",
    "y_xor = np.array([0, 1, 1, 0])\n",
    "w_1 = np.array([\n",
    "    [-3/2, -1/2],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "])\n",
    "\n",
    "# intermediate \"hidden\" space - inputs to the next layer\n",
    "H = step(X @ w_1)\n",
    "\n",
    "# add on the bias term for the hidden layer\n",
    "H = np.column_stack((np.ones(4), H))\n",
    "w_2 = np.array([-0.5, -1, 1])\n",
    "\n",
    "fig_h, ax_h = plot_inputs(H, y_xor)\n",
    "plot_decision(ax_h, w_2, label=\"Decision boundary for layer 2\")\n",
    "ax_h.set_aspect(\"auto\")\n",
    "ax_h.set_xlabel(\"$h_1$\")\n",
    "ax_h.set_ylabel(\"$h_2$\")\n",
    "ax_h.legend()\n",
    "\n",
    "print(step(H @ w_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy mlp example\n",
    "# forward pass\n",
    "X = np.array([2, 3])\n",
    "y = 1\n",
    "W1 = np.array([[-0.78, 0.13], [0.85, 0.23]])\n",
    "W2 = np.array([1.8, 0.40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X @ W1 @ W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterations = 20\n",
    "eta = 0.01\n",
    "loss = np.zeros(iterations)\n",
    "\n",
    "for i in range(iterations):\n",
    "    # forward pass\n",
    "    y_hat = X @ W1 @ W2\n",
    "    \n",
    "    # update loss to keep track of performance\n",
    "    loss[i] = (y_hat - y)**2\n",
    "\n",
    "    # backpropagate!\n",
    "    w2_partials = (y_hat - y) * (X @ W1)\n",
    "    w1_partials = w2_partials @ X\n",
    "\n",
    "    # take a step in the opposite direction\n",
    "    W1 = W1 - eta * w1_partials\n",
    "    W2 = W2 - eta * w2_partials\n",
    "\n",
    "plt.plot(loss)\n",
    "\n",
    "# check how well we did\n",
    "print(\"Final prediction:\", X @ W1 @ W2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
